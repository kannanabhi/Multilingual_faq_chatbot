{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lpMbvMwYUNSY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Installation Files"
      ],
      "metadata": {
        "id": "NeS4BTA6yV7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKg33o_BZWor",
        "outputId": "b7c1e992-7e93-4e39-ef04-bddb8e0d7f04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,sys\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0,nb_path)"
      ],
      "metadata": {
        "id": "l-5tT4j6NLUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd notebooks"
      ],
      "metadata": {
        "id": "aa_PZRx1R7lv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8767a9f-0f54-4f02-cdc0-7ffaf87a8013"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: notebooks: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qQQm6OeSDFN",
        "outputId": "8d1ef529-0da0-4108-a13a-e4a799e69372"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/mandir_project\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "xux3SpmyfQkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da17f36-f648-4b32-e580-a675a535e73b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/mandir_project': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"/content/mandir_project\"\n",
        "!cp -r \"/content/drive/MyDrive/mandir_project\" \"/content/mandir_project\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgOwn7LqftpJ",
        "outputId": "117f3b3e-6e08-4479-9338-eca0691c3641"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/mandir_project': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --target=$nb_path rasa==1.10.3\n",
        "!pip install rasa\n",
        "#restart runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1RK4rU6zyOq6",
        "outputId": "c286d440-a28c-4d35-caba-e920147a4aef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rasa\n",
            "  Downloading rasa-3.6.0-py3-none-any.whl (830 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m830.4/830.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting CacheControl<0.13.0,>=0.12.9 (from rasa)\n",
            "  Downloading CacheControl-0.12.14-py2.py3-none-any.whl (21 kB)\n",
            "Collecting PyJWT[crypto]<3.0.0,>=2.0.0 (from rasa)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting SQLAlchemy<1.5.0,>=1.4.0 (from rasa)\n",
            "  Downloading SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py<1.5,>=0.9 in /usr/local/lib/python3.10/dist-packages (from rasa) (1.4.0)\n",
            "Collecting aio-pika<8.2.4,>=6.7.1 (from rasa)\n",
            "  Downloading aio_pika-8.2.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiogram<2.26 (from rasa)\n",
            "  Downloading aiogram-2.25.1-py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=3.7.4.post0,<3.9,>=3.6 (from rasa)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting apscheduler<3.10,>=3.6 (from rasa)\n",
            "  Downloading APScheduler-3.9.1.post1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs<22.2,>=19.3 (from rasa)\n",
            "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0.0,>=1.26.136 (from rasa)\n",
            "  Downloading boto3-1.26.160-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<2.3,>=1.2 in /usr/local/lib/python3.10/dist-packages (from rasa) (2.2.1)\n",
            "Collecting colorclass<2.3,>=2.2 (from rasa)\n",
            "  Downloading colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting coloredlogs<16,>=10 (from rasa)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorhash<1.3.0,>=1.0.2 (from rasa)\n",
            "  Downloading colorhash-1.2.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting confluent-kafka<3.0.0,>=1.9.2 (from rasa)\n",
            "  Downloading confluent_kafka-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask==2022.10.2 (from rasa)\n",
            "  Downloading dask-2022.10.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fbmessenger<6.1.0,>=6.0.0 (from rasa)\n",
            "  Downloading fbmessenger-6.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: google-auth<3 in /usr/local/lib/python3.10/dist-packages (from rasa) (2.17.3)\n",
            "Requirement already satisfied: joblib<1.3.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from rasa) (1.2.0)\n",
            "Requirement already satisfied: jsonpickle<3.1,>=1.3 in /usr/local/lib/python3.10/dist-packages (from rasa) (3.0.1)\n",
            "Requirement already satisfied: jsonschema<4.18,>=3.2 in /usr/local/lib/python3.10/dist-packages (from rasa) (4.3.3)\n",
            "Collecting matplotlib<3.6,>=3.1 (from rasa)\n",
            "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mattermostwrapper<2.3,>=2.2 (from rasa)\n",
            "  Downloading mattermostwrapper-2.2.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx<2.7,>=2.4 (from rasa)\n",
            "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.25.0,>=1.19.2 in /usr/local/lib/python3.10/dist-packages (from rasa) (1.22.4)\n",
            "Collecting packaging<21.0,>=20.0 (from rasa)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from rasa) (1.2.0)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from rasa)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting prompt-toolkit<3.0.29,>=3.0 (from rasa)\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2 (from rasa)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg2-binary<2.10.0,>=2.8.2 (from rasa)\n",
            "  Downloading psycopg2_binary-2.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<1.10.3 (from rasa)\n",
            "  Downloading pydantic-1.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot<1.5,>=1.4 in /usr/local/lib/python3.10/dist-packages (from rasa) (1.4.2)\n",
            "Collecting pykwalify<1.9,>=1.7 (from rasa)\n",
            "  Downloading pykwalify-1.8.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pymongo[srv,tls]<4.4,>=3.8 (from rasa)\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from rasa) (2.8.2)\n",
            "Collecting python-engineio!=5.0.0,<6,>=4 (from rasa)\n",
            "  Downloading python_engineio-4.4.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-socketio<6,>=4.4 (from rasa)\n",
            "  Downloading python_socketio-5.8.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz<2023.0,>=2019.1 in /usr/local/lib/python3.10/dist-packages (from rasa) (2022.7.1)\n",
            "Collecting pyyaml<6.0,>=5.3.1 (from rasa)\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting questionary<1.11.0,>=1.5.1 (from rasa)\n",
            "  Downloading questionary-1.10.0-py3-none-any.whl (31 kB)\n",
            "Collecting randomname<0.2.0,>=0.1.5 (from rasa)\n",
            "  Downloading randomname-0.1.5.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rasa-sdk<3.7.0,>=3.6.0 (from rasa)\n",
            "  Downloading rasa_sdk-3.6.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis<5.0,>=4.5.3 (from rasa)\n",
            "  Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex<2022.11,>=2020.6 in /usr/local/lib/python3.10/dist-packages (from rasa) (2022.10.31)\n",
            "Requirement already satisfied: requests<3.0,>=2.23 in /usr/local/lib/python3.10/dist-packages (from rasa) (2.27.1)\n",
            "Collecting rocketchat_API<1.31.0,>=0.6.31 (from rasa)\n",
            "  Downloading rocketchat_API-1.30.0-py3-none-any.whl (21 kB)\n",
            "Collecting ruamel.yaml<0.18.0,>=0.16.5 (from rasa)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic<21.13,>=21.12 (from rasa)\n",
            "  Downloading sanic-21.12.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic-cors<2.1.0,>=2.0.0 (from rasa)\n",
            "  Downloading Sanic_Cors-2.0.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting sanic-jwt<2.0.0,>=1.6.0 (from rasa)\n",
            "  Downloading sanic_jwt-1.8.0-py3-none-any.whl (23 kB)\n",
            "Collecting sanic-routing<0.8.0,>=0.7.2 (from rasa)\n",
            "  Downloading sanic_routing-0.7.2-py3-none-any.whl (23 kB)\n",
            "Collecting scikit-learn<1.2,>=0.22 (from rasa)\n",
            "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.9.0,>=1.4.1 (from rasa)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk<1.15.0,>=0.17.0 (from rasa)\n",
            "  Downloading sentry_sdk-1.14.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from rasa) (67.7.2)\n",
            "Collecting sklearn-crfsuite<0.4,>=0.3 (from rasa)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting slack-sdk<4.0.0,>=3.19.2 (from rasa)\n",
            "  Downloading slack_sdk-3.21.3-py2.py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/276.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting structlog<24.0.0,>=23.1.0 (from rasa)\n",
            "  Downloading structlog-23.1.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting structlog-sentry<3.0.0,>=2.0.2 (from rasa)\n",
            "  Downloading structlog_sentry-2.0.3-py3-none-any.whl (10 kB)\n",
            "Collecting tarsafe<0.0.5,>=0.0.3 (from rasa)\n",
            "  Downloading tarsafe-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting tensorflow==2.11.1 (from rasa)\n",
            "  Downloading tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons<0.20,>=0.18 (from rasa)\n",
            "  Downloading tensorflow_addons-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text==2.11.0 (from rasa)\n",
            "  Downloading tensorflow_text-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_hub<0.13.0,>=0.12.0 (from rasa)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminaltables<3.2.0,>=3.1.0 (from rasa)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.31 in /usr/local/lib/python3.10/dist-packages (from rasa) (4.65.0)\n",
            "Collecting twilio<8.3,>=6.26 (from rasa)\n",
            "  Downloading twilio-8.2.2-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from rasa) (4.6.3)\n",
            "Collecting typing-utils<0.2.0,>=0.1.0 (from rasa)\n",
            "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
            "Collecting ujson<6.0,>=1.35 (from rasa)\n",
            "  Downloading ujson-5.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webexteamssdk<1.7.0,>=1.1.1 (from rasa)\n",
            "  Downloading webexteamssdk-1.6.1-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from rasa)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa) (8.1.3)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa) (2023.6.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa) (1.4.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa) (0.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (1.54.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (3.8.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.1->rasa)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (1.16.0)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.1->rasa)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.1->rasa)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1->rasa) (0.32.0)\n",
            "Collecting aiormq~=6.4.0 (from aio-pika<8.2.4,>=6.7.1->rasa)\n",
            "  Downloading aiormq-6.4.2-py3-none-any.whl (34 kB)\n",
            "Collecting yarl (from aio-pika<8.2.4,>=6.7.1->rasa)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Babel<2.10.0,>=2.9.1 (from aiogram<2.26->rasa)\n",
            "  Downloading Babel-2.9.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from aiogram<2.26->rasa) (2023.5.7)\n",
            "Collecting magic-filter>=1.0.9 (from aiogram<2.26->rasa)\n",
            "  Downloading magic_filter-1.0.9-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: tzlocal!=3.*,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<3.10,>=3.6->rasa) (5.0.1)\n",
            "Collecting botocore<1.30.0,>=1.29.160 (from boto3<2.0.0,>=1.26.136->rasa)\n",
            "  Downloading botocore-1.29.160-py3-none-any.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.26.136->rasa)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<2.0.0,>=1.26.136->rasa)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from CacheControl<0.13.0,>=0.12.9->rasa) (1.0.5)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs<16,>=10->rasa)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa) (4.9)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=3.2->rasa) (0.19.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa) (3.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.0.29,>=3.0->rasa) (0.2.6)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3.0.0,>=2.0.0->rasa) (41.0.1)\n",
            "Collecting docopt>=0.6.2 (from pykwalify<1.9,>=1.7->rasa)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo[srv,tls]<4.4,>=3.8->rasa)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bidict>=0.21.0 (from python-socketio<6,>=4.4->rasa)\n",
            "  Downloading bidict-0.22.1-py3-none-any.whl (35 kB)\n",
            "Collecting fire (from randomname<0.2.0,>=0.1.5->rasa)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa) (3.4)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<0.18.0,>=0.16.5->rasa)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.0.10 (from sanic<21.13,>=21.12->rasa)\n",
            "  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles>=0.6.0 (from sanic<21.13,>=21.12->rasa)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa)\n",
            "  Downloading multidict-5.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop>=0.5.3 (from sanic<21.13,>=21.12->rasa)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2,>=0.22->rasa) (3.1.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite<0.4,>=0.3->rasa)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite<0.4,>=0.3->rasa) (0.8.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<1.5.0,>=1.4.0->rasa) (2.0.2)\n",
            "Collecting typeguard>=2.7 (from tensorflow-addons<0.20,>=0.18->rasa)\n",
            "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
            "Collecting aiohttp-retry>=2.8.3 (from twilio<8.3,>=6.26->rasa)\n",
            "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from webexteamssdk<1.7.0,>=1.1.1->rasa) (0.18.3)\n",
            "Collecting requests-toolbelt (from webexteamssdk<1.7.0,>=1.1.1->rasa)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pamqp==3.2.1 (from aiormq~=6.4.0->aio-pika<8.2.4,>=6.7.1->rasa)\n",
            "  Downloading pamqp-3.2.1-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.1->rasa) (0.40.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.0->PyJWT[crypto]<3.0.0,>=2.0.0->rasa) (1.15.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask==2022.10.2->rasa) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3->rasa) (0.5.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa) (3.4.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa) (2.3.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.0->PyJWT[crypto]<3.0.0,>=2.0.0->rasa) (2.21)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1->rasa) (3.2.2)\n",
            "Building wheels for collected packages: mattermostwrapper, pyyaml, randomname, docopt, fire\n",
            "  Building wheel for mattermostwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mattermostwrapper: filename=mattermostwrapper-2.2-py3-none-any.whl size=2448 sha256=046fd5300859c9f9f58905772bbf214b605e6974d455bf202778108253bf92f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/dc/02/e3239f0ea0a676085826846d32ef09b10915c0a33c817d2dbb\n",
            "  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=4285ebd9f4b206cc0f92142caaca282b81c309fb1c922610f71527058b2879e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for randomname: filename=randomname-0.1.5-py3-none-any.whl size=58808 sha256=bc304f48894bc495269f717ade18ae24ecc3df95176326b0edf8cfc19da7f8fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/df/c1/0bdf17c694217f49657ca36fd0239b9a243c34c27a70ff56ef\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=618c5b05473f60cc59abf7ee60a2c0e06a7665e1961bd259eb46c92601859d89\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=24a04963b3c970a9b8b1a006f4247d058cda3171b14f49460278e423979ac075\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built mattermostwrapper pyyaml randomname docopt fire\n",
            "Installing collected packages: tensorboard-plugin-wit, sanic-routing, python-crfsuite, docopt, confluent-kafka, websockets, uvloop, ujson, typing-utils, typeguard, terminaltables, tensorflow-estimator, tensorboard-data-server, tarsafe, structlog, SQLAlchemy, slack-sdk, sklearn-crfsuite, sentry-sdk, scipy, ruamel.yaml.clib, pyyaml, python-engineio, PyJWT, pydantic, psycopg2-binary, protobuf, prompt-toolkit, portalocker, pamqp, packaging, networkx, multidict, magic-filter, keras, jmespath, humanfriendly, httptools, frozenlist, fire, dnspython, colorhash, colorclass, bidict, Babel, attrs, async-timeout, apscheduler, aiofiles, yarl, tensorflow_hub, tensorflow-addons, structlog-sentry, scikit-learn, sanic-jwt, sanic, ruamel.yaml, rocketchat_API, requests-toolbelt, redis, randomname, questionary, python-socketio, pymongo, mattermostwrapper, matplotlib, fbmessenger, dask, coloredlogs, CacheControl, botocore, aiosignal, webexteamssdk, sanic-cors, s3transfer, pykwalify, google-auth-oauthlib, aiormq, aiohttp, tensorboard, rasa-sdk, boto3, aiohttp-retry, aiogram, aio-pika, twilio, tensorflow, tensorflow-text, rasa\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.1\n",
            "    Uninstalling tensorboard-data-server-0.7.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.16\n",
            "    Uninstalling SQLAlchemy-2.0.16:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.16\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.9\n",
            "    Uninstalling pydantic-1.10.9:\n",
            "      Successfully uninstalled pydantic-1.10.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.38\n",
            "    Uninstalling prompt-toolkit-3.0.38:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.38\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.12.1\n",
            "    Uninstalling Babel-2.12.1:\n",
            "      Successfully uninstalled Babel-2.12.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "  Attempting uninstall: tensorflow_hub\n",
            "    Found existing installation: tensorflow-hub 0.13.0\n",
            "    Uninstalling tensorflow-hub-0.13.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.13.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.12.1\n",
            "    Uninstalling dask-2022.12.1:\n",
            "      Successfully uninstalled dask-2022.12.1\n",
            "  Attempting uninstall: CacheControl\n",
            "    Found existing installation: CacheControl 0.13.1\n",
            "    Uninstalling CacheControl-0.13.1:\n",
            "      Successfully uninstalled CacheControl-0.13.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "distributed 2022.12.1 requires dask==2022.12.1, but you have dask 2022.10.2 which is incompatible.\n",
            "statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Babel-2.9.1 CacheControl-0.12.14 PyJWT-2.7.0 SQLAlchemy-1.4.48 aio-pika-8.2.3 aiofiles-23.1.0 aiogram-2.25.1 aiohttp-3.8.4 aiohttp-retry-2.8.3 aiormq-6.4.2 aiosignal-1.3.1 apscheduler-3.9.1.post1 async-timeout-4.0.2 attrs-22.1.0 bidict-0.22.1 boto3-1.26.160 botocore-1.29.160 colorclass-2.2.2 coloredlogs-15.0.1 colorhash-1.2.1 confluent-kafka-2.1.1 dask-2022.10.2 dnspython-2.3.0 docopt-0.6.2 fbmessenger-6.0.0 fire-0.5.0 frozenlist-1.3.3 google-auth-oauthlib-0.4.6 httptools-0.5.0 humanfriendly-10.0 jmespath-1.0.1 keras-2.11.0 magic-filter-1.0.9 matplotlib-3.5.3 mattermostwrapper-2.2 multidict-5.2.0 networkx-2.6.3 packaging-20.9 pamqp-3.2.1 portalocker-2.7.0 prompt-toolkit-3.0.28 protobuf-3.19.6 psycopg2-binary-2.9.6 pydantic-1.10.2 pykwalify-1.8.0 pymongo-4.3.3 python-crfsuite-0.9.9 python-engineio-4.4.1 python-socketio-5.8.0 pyyaml-5.4.1 questionary-1.10.0 randomname-0.1.5 rasa-3.6.0 rasa-sdk-3.6.0 redis-4.6.0 requests-toolbelt-1.0.0 rocketchat_API-1.30.0 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 s3transfer-0.6.1 sanic-21.12.2 sanic-cors-2.0.1 sanic-jwt-1.8.0 sanic-routing-0.7.2 scikit-learn-1.1.3 scipy-1.8.1 sentry-sdk-1.14.0 sklearn-crfsuite-0.3.6 slack-sdk-3.21.3 structlog-23.1.0 structlog-sentry-2.0.3 tarsafe-0.0.4 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.1 tensorflow-addons-0.19.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0 tensorflow_hub-0.12.0 terminaltables-3.1.10 twilio-8.2.2 typeguard-4.0.0 typing-utils-0.1.0 ujson-5.8.0 uvloop-0.17.0 webexteamssdk-1.6.1 websockets-10.4 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits",
                  "packaging",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spacy is NLP library and it interacts with rasa to give our results"
      ],
      "metadata": {
        "id": "52MkXouAqtjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-aXPdZkaaAa",
        "outputId": "490e6176-b313-48e4-dc54-af3f2103ad2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-26 07:06:57.606897: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-26 07:06:58.961087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-06-26 07:06:58.961277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-06-26 07:06:58.961297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-06-26 07:07:02.141184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-06-26 07:07:02.141239: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (20.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "# !python -m spacy download en --target=$nb_path\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used to run jupyter notebook in asynchronous mode. (its version is drectly dependent on version of rasa"
      ],
      "metadata": {
        "id": "3fsWyr1Sq47a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTyu0zyi7nNG",
        "outputId": "6627f40e-8744-4498-92bd-61cc42467b1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install nest_asyncio==1.3.3\n",
        "#restart runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cway5Uxxz_7W",
        "outputId": "cdbe0787-e248-4c1a-9556-18057fdf0c5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nest_asyncio==1.3.3\n",
            "  Downloading nest_asyncio-1.3.3-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: nest_asyncio\n",
            "  Attempting uninstall: nest_asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.6\n",
            "    Uninstalling nest-asyncio-1.5.6:\n",
            "      Successfully uninstalled nest-asyncio-1.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.4.8 requires nest-asyncio>=1.5, but you have nest-asyncio 1.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nest_asyncio-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing the required libraries"
      ],
      "metadata": {
        "id": "O6nE0uYe0Izt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasa\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "print(\"event loop ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBP---a80M3E",
        "outputId": "5413c0d4-b43c-4dd9-8ad9-4d8a27107306"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "event loop ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rasa.cli.scaffold import create_initial_project"
      ],
      "metadata": {
        "id": "sk-macG6r1rY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***do not run this multiple times***"
      ],
      "metadata": {
        "id": "lg9_ifl_kkGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project='mandir_project'\n",
        "create_initial_project(project)"
      ],
      "metadata": {
        "id": "A_LjqSyXr76O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to move to the correct folder"
      ],
      "metadata": {
        "id": "CD3LDhSCsf0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(project)\n",
        "print(os.listdir(\".\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtFKabF3sMhF",
        "outputId": "aef4d61b-0b31-4d71-de92-f9965a5c6eb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['actions.py', 'endpoints.yml', 'models', 'config.yml', 'data', 'tests', '__init__.py', 'credentials.yml', '__pycache__', 'actions', 'domain.yml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are creating variables to represnt many files"
      ],
      "metadata": {
        "id": "TQraBUHcsmIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config=\"config.yml\"\n",
        "training_files=\"data/\"\n",
        "domain=\"domain.yml\"\n",
        "output=\"models/\"\n",
        "print(config,training_files,domain,output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfpHEERhtAwf",
        "outputId": "c967e98b-00a4-4c54-dd49-ba038e9bfec3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yml data/ domain.yml models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=rasa.train(domain,config,[training_files],output)\n",
        "\n",
        "#model_path='http://my-server.com/models/default_core@latest'\n",
        "print(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aODArkL3tRo3",
        "outputId": "1ba17424-f769-4336-90c1-f799b0a233b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/engine/caching.py:152: MovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base: DeclarativeMeta = declarative_base()\n",
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b(0lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\u001b(B\n",
            "\u001b(0x\u001b(B Rasa Open Source reports anonymous usage telemetry to help improve the product \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B for all its users.                                                             \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B                                                                                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B If you'd like to opt-out, you can use `rasa telemetry disable`.                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B To learn more, check out https://rasa.com/docs/rasa/telemetry/telemetry.       \u001b(0x\u001b(B\n",
            "\u001b(0mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\u001b(B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mThe configuration for policies and pipeline was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpochs:   0%|          | 0/100 [00:00<?, ?it/s]WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "/usr/lib/python3.10/random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
            "  return self.randrange(a, b+1)\n",
            "Epochs: 100%|██████████| 100/100 [00:51<00:00,  1.94it/s, t_loss=1.15, i_acc=1]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 207.85it/s, # trackers=1]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 216.45it/s, # trackers=3]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 84.93it/s, # trackers=12]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 33.85it/s, # trackers=39]\n",
            "Processed rules: 100%|██████████| 2/2 [00:00<00:00, 241.27it/s, # trackers=1]\n",
            "Processed trackers: 100%|██████████| 3/3 [00:00<00:00, 150.22it/s, # action=12]\n",
            "Processed actions: 12it [00:00, 789.74it/s, # examples=12]\n",
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 168.01it/s, # action=5]\n",
            "Processed actions: 5it [00:00, 1099.25it/s, # examples=4]\n",
            "Processed trackers: 100%|██████████| 3/3 [00:00<00:00, 116.25it/s, # action=12]\n",
            "Processed trackers:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: goodbye | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: goodbye | previous action name: action_listen\n",
            "[state 3] user intent: goodbye | previous action name: utter_goodbye\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: bot_challenge | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: bot_challenge | previous action name: action_listen\n",
            "[state 3] user intent: bot_challenge | previous action name: utter_iamabot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 191.93it/s]\n",
            "Processed trackers:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_great | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_great | previous action name: action_listen\n",
            "[state 4] user intent: mood_great | previous action name: utter_happy\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "[state 6] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "[state 6] user intent: affirm | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "[state 6] user intent: affirm | previous action name: action_listen\n",
            "[state 7] user intent: affirm | previous action name: utter_happy\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "[state 6] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "[state 6] user intent: deny | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] user intent: greet | previous action name: action_listen\n",
            "[state 2] user intent: greet | previous action name: utter_greet\n",
            "[state 3] user intent: mood_unhappy | previous action name: action_listen\n",
            "[state 4] user intent: mood_unhappy | previous action name: utter_cheer_up\n",
            "[state 5] user intent: mood_unhappy | previous action name: utter_did_that_help\n",
            "[state 6] user intent: deny | previous action name: action_listen\n",
            "[state 7] user intent: deny | previous action name: utter_goodbye\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: goodbye | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: goodbye | previous action name: action_listen\n",
            "[state 3] user intent: goodbye | previous action name: utter_goodbye\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: bot_challenge | previous action name: action_listen\n",
            "2023-06-26 07:18:48 [debug    ] rule_policy.actions.find       current_states=\n",
            "[state 1] previous action name: ...\n",
            "[state 2] user intent: bot_challenge | previous action name: action_listen\n",
            "[state 3] user intent: bot_challenge | previous action name: utter_iamabot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed trackers: 100%|██████████| 5/5 [00:00<00:00, 71.71it/s]\n",
            "Processed trackers: 100%|██████████| 120/120 [00:00<00:00, 637.77it/s, # action=30]\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(ragged_array)\n",
            "Epochs: 100%|██████████| 100/100 [00:29<00:00,  3.38it/s, t_loss=2.08, loss=1.92, acc=1]\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n",
            "Processed trackers: 100%|██████████| 120/120 [00:00<00:00, 1427.65it/s, # intent=12]\n",
            "Epochs: 100%|██████████| 100/100 [00:25<00:00,  3.95it/s, t_loss=0.122, loss=0.0106, acc=1]\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/core/policies/unexpected_intent_policy.py:839: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
            "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they. (Deprecated NumPy 1.22)\n",
            "  quantile_values = np.quantile(  # type: ignore[call-overload]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0edb2f573f32>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrasa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model_path='http://my-server.com/models/default_core@latest'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/api.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(domain, config, training_files, output, dry_run, force_training, fixed_model_name, persist_nlu_training_data, core_additional_arguments, nlu_additional_arguments, model_to_finetune, finetuning_epoch_fraction)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mrasa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     return train(\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/model_training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(domain, config, training_files, output, dry_run, force_training, fixed_model_name, persist_nlu_training_data, core_additional_arguments, nlu_additional_arguments, model_to_finetune, finetuning_epoch_fraction)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_model_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_importer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rasa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         return _train_graph(\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mfile_importer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mtraining_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/model_training.py\u001b[0m in \u001b[0;36m_train_graph\u001b[0;34m(file_importer, training_type, output_path, fixed_model_name, model_to_finetune, force_full_training, dry_run, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mfile_importer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         ):\n\u001b[0;32m--> 286\u001b[0;31m             trainer.train(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0mmodel_configuration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mfile_importer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/engine/training/graph_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_configuration, importer, output_filename, force_retraining, is_finetuning)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mgraph_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mPLACEHOLDER_IMPORTER\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimporter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         return self._model_storage.create_model_package(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/engine/storage/local_model_storage.py\u001b[0m in \u001b[0;36mcreate_model_package\u001b[0;34m(self, model_archive_path, model_configuration, domain)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTarSafe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_archive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w:gz\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemporary_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model package created in path '{model_archive_path}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2179\u001b[0;31m                     self.add(os.path.join(name, f), os.path.join(arcname, f),\n\u001b[0m\u001b[1;32m   2180\u001b[0m                             recursive, filter=filter)\n\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2179\u001b[0;31m                     self.add(os.path.join(name, f), os.path.join(arcname, f),\n\u001b[0m\u001b[1;32m   2180\u001b[0m                             recursive, filter=filter)\n\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2179\u001b[0;31m                     self.add(os.path.join(name, f), os.path.join(arcname, f),\n\u001b[0m\u001b[1;32m   2180\u001b[0m                             recursive, filter=filter)\n\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mbltn_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36maddfile\u001b[0;34m(self, tarinfo, fileobj)\u001b[0m\n\u001b[1;32m   2199\u001b[0m         \u001b[0;31m# If there's data to follow, append it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m             \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the following code can be used to chat with the chatbot"
      ],
      "metadata": {
        "id": "9t3hzzh-uN_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rasa.jupyter import chat\n",
        "\n",
        "endpoints= 'endpoints.yml'\n",
        "entries=[]\n",
        "chat(model_path,endpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6YrV8K-FuAmm",
        "outputId": "9a35367d-135b-4bc4-e845-33fbd0108d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fd9d2b47bb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mendpoints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'endpoints.yml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mendpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/rasa/jupyter.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(model_path, endpoints, agent)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         agent = asyncio.run(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mrasa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(future, debug)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event loop stopped before Future completed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/rasa/core/agent.py\u001b[0m in \u001b[0;36mload_agent\u001b[0;34m(model_path, model_server, remote_storage, endpoints, loop)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mendpoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mbroker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mEventBroker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_broker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         tracker_store = TrackerStore.create(\n\u001b[1;32m    226\u001b[0m             \u001b[0mendpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_broker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbroker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'event_broker'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(model_path,endpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "8vC1AterjP7E",
        "outputId": "35fb66e6-e10d-4944-f229-dac4f95f2390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-6ebcf98aa8e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mendpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-7a3317cab66c>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(model_path, endpoints, agent)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         agent = asyncio.run(\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mrasa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: load_agent() got an unexpected keyword argument 'endpoints'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to chat with chatbot again, don't import it from scratch. Just use the following commands"
      ],
      "metadata": {
        "id": "P5qpdYUkuUIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat(model_path,endpoints)"
      ],
      "metadata": {
        "id": "ppSq4Cjcub3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifying chatbot for our needs"
      ],
      "metadata": {
        "id": "lpMbvMwYUNSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "editing the doman.yml file and nlu.md file and stories.md file"
      ],
      "metadata": {
        "id": "zn_DE9bNUT-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data/nlu.md\n",
        "## intent:greet\n",
        "- hey\n",
        "- hello\n",
        "- hi\n",
        "- good morning\n",
        "- good evening\n",
        "- hey there\n",
        "\n",
        "## intent:goodbye\n",
        "- bye\n",
        "- goodbye\n",
        "- see you around\n",
        "- see you later\n",
        "\n",
        "## intent:affirm\n",
        "- yes\n",
        "- indeed\n",
        "- of course\n",
        "- that sounds good\n",
        "- correct\n",
        "\n",
        "## intent:deny\n",
        "- no\n",
        "- never\n",
        "- I don't think so\n",
        "- don't like that\n",
        "- no way\n",
        "- not really\n",
        "\n",
        "## intent:bot_challenge\n",
        "- are you a bot?\n",
        "- are you a human?\n",
        "- am I talking to a bot?\n",
        "- am I talking to a human?\n",
        "\n",
        "## intent: location\n",
        "\t\t- location?\n",
        "\t\t- where is the temple located?\n",
        "\t\t- where is the temple?\n",
        "\n",
        "## intent: info_material\n",
        "\t\t- What is the temple made of?\n",
        "\n",
        "## intent: info_history\n",
        "\n",
        "\n",
        "\n",
        "## intent: info_timings\n",
        "\t\t- what are the timings of the temple?\n",
        "\t\t- when can we go to the temple?\n",
        "\t\t- when will the temple be open?\n",
        "\t\t- when should I visit the temple?\n",
        "\n",
        "## intent: significance\n",
        "\t- what is significance?\n",
        "\t- what does the temple signify?\n",
        "\t- what is special about this temple?\n",
        "\n",
        "## intent: reachability\n",
        "\t- how to reach this temple\n",
        "\t- what is nearest airport?\n",
        "\t- what is nearest railway station?\n",
        "\t- how do I reach the temple\n",
        "\n",
        "## intent: build_time\n",
        "\t- when was the temple built?\n",
        "\t- when temple constructed?\n",
        "\t- when temple made?\n",
        "\t- When was the temple made?\n",
        "\t- when was the temple created?\n",
        "\n",
        "## intent: cost\n",
        "\t- what is entry fees?\n",
        "\t- entry cost of temple\n",
        "\t- what is ticket price of temple?\n",
        "\t- how much does a ticket cost?\n",
        "\n",
        "## intent: other_attractions\n",
        "\t- what are other attractions nearby?\n",
        "\t- what else can we visit nearby?\n",
        "\t- what places to visit near?\n",
        "\n"
      ],
      "metadata": {
        "id": "-gs9MBGrUkfy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ed3a1601-9022-4b04-aaac-38397afbd762"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data/nlu.md\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c6089f6d81fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/nlu.md'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"## intent:greet\\n- hey\\n- hello\\n- hi\\n- good morning\\n- good evening\\n- hey there\\n\\n## intent:goodbye\\n- bye\\n- goodbye\\n- see you around\\n- see you later\\n\\n## intent:affirm\\n- yes\\n- indeed\\n- of course\\n- that sounds good\\n- correct\\n\\n## intent:deny\\n- no\\n- never\\n- I don't think so\\n- don't like that\\n- no way\\n- not really\\n\\n## intent:bot_challenge\\n- are you a bot?\\n- are you a human?\\n- am I talking to a bot?\\n- am I talking to a human?\\n\\n## intent: location\\n\\t\\t- location?\\n\\t\\t- where is the temple located?\\n\\t\\t- where is the temple?\\n\\n## intent: info_material\\n\\t\\t- What is the temple made of?\\n\\n## intent: info_history\\n\\n\\n\\n## intent: info_timings\\n\\t\\t- what are the timings of the temple?\\n\\t\\t- when can we go to the temple?\\n\\t\\t- when will the temple be open?\\n\\t\\t- when should I visit the temple?\\n\\n## intent: significance\\n\\t- what is significance?\\n\\t- what does the temple signify?\\n\\t- what is special about this temple?\\n\\n## intent: reachability\\n\\t- how to reach this temple\\n\\t- what is nearest airport?\\n\\t- what is nearest railway station?\\n\\t- how do I reach the temple\\n\\n## intent: build_time\\n\\t- when was the temple built?\\n\\t- when temple constructed?\\n\\t- when temple made?\\n\\t- When was the temple made?\\n\\t- when was the temple created?\\n\\n## intent...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/nlu.md'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile domain.yml\n",
        "intents:\n",
        "  - greet\n",
        "  - goodbye\n",
        "  - affirm\n",
        "  - deny\n",
        "  - bot_challenge\n",
        "  - location\n",
        "  - reachability\n",
        "  - info_timings\n",
        "  - info_material\n",
        "  - info_history\n",
        "  - significance\n",
        "  - build_time\n",
        "  - cost\n",
        "  - other_attractions\n",
        "\n",
        "responses:\n",
        "  utter_greet:\n",
        "  - text: \"Hey! How are you?\"\n",
        "\n",
        "  utter_did_that_help:\n",
        "  - text: \"Did that help you?\"\n",
        "\n",
        "  utter_goodbye:\n",
        "  - text: \"Bye\"\n",
        "\n",
        "  utter_iamabot:\n",
        "  - text: \"I am a bot, powered by Rasa.\"\n",
        "\n",
        "  utter_location:\n",
        "  - text: \"temple is located in Bits Pilani near T-lawns\"\n",
        "\n",
        "  utter_reachability:\n",
        "  - text: \"Loharu to bits pilani \"\n",
        "\n",
        "  utter_info_timings:\n",
        "  - text: \"everyday from morning 8am to evening 7pm (except for special holidays) \"\n",
        "\n",
        "  utter_info_material:\n",
        "  - text: \" temple is made of white marble and other material \"\n",
        "\n",
        "  utter_info_history:\n",
        "  - text: \"temple constructed by Birla foundation in honour of Goddess Saraswathy\"\n",
        "\n",
        "  utter_significance:\n",
        "  - text: \"The temple is dedicated to Laxmi (the goddess of prosperity) and Narayana (The preserver) \"\n",
        "\n",
        "  utter_build_time:\n",
        "  - text: \"very old temple\"\n",
        "\n",
        "  utter_cost:\n",
        "  - text: \"net expense unknown\"\n",
        "\n",
        "  utter_other_attractions:\n",
        "  - text: \"Birla Museum, Student Activity Centre and Sky Lawns\"\n",
        "\n",
        "session_config:\n",
        "  session_expiration_time: 60\n",
        "  carry_over_slots_to_new_session: true\n"
      ],
      "metadata": {
        "id": "PyQVtGjWUxdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data/stories.md\n",
        "## ques onePath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* location\n",
        "  - utter_location\n",
        "\n",
        "\n",
        "## ques twoPath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* reachability\n",
        "  - utter_reachability\n",
        "\n",
        "## ques threePath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* info_timings\n",
        "  - utter_info_timings\n",
        "\n",
        "## ques fourPath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* info_history\n",
        "  - utter_info_history\n",
        "\n",
        "## ques fivePath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* info_material\n",
        "  - utter_info_material\n",
        "\n",
        "## ques sixPath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* significance\n",
        "  - utter_significance\n",
        "\n",
        "## ques sevenPath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* cost\n",
        "  - utter_cost\n",
        "\n",
        "## ques eightPath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* other_attractions\n",
        "  - utter_other_attractions\n",
        "\n",
        "## ques ninePath\n",
        "* greet\n",
        "  - utter_greet\n",
        "* build_time\n",
        "  - utter_build_time\n",
        "\n",
        "## say goodbye\n",
        "* goodbye\n",
        "  - utter_goodbye\n",
        "\n",
        "## bot challenge\n",
        "* bot_challenge\n",
        "  - utter_iamabot"
      ],
      "metadata": {
        "id": "yP5qA9imUuig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google translate API"
      ],
      "metadata": {
        "id": "e3rVrYu7e0PO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kymCE2GrfIgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==4.0.0rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "ym4B1LfRfHsf",
        "outputId": "8b974af7-d309-48f3-8a12-92270868a522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==4.0.0rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (3.0.4)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.5.0)\n",
            "Collecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2022.9.24)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2.10)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2022.11.1)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (0.8.1)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (5.2.0)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17414 sha256=ccb8b93cf66e0a72190ff4cadf6ad7bf0da664329853d8de08587680b05c48d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/00/4fe71786ea6d12314b29037620c36d857e5d104ac2748bf82a\n",
            "Successfully built googletrans\n",
            "Installing collected packages: httpcore, httpx, googletrans\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.9.3\n",
            "    Uninstalling httpx-0.9.3:\n",
            "      Successfully uninstalled httpx-0.9.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sanic 19.12.2 requires httpx==0.9.3, but you have httpx 0.13.3 which is incompatible.\u001b[0m\n",
            "Successfully installed googletrans-4.0.0rc1 httpcore-0.9.1 httpx-0.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "httpx"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googletrans\n",
        "from googletrans import Translator"
      ],
      "metadata": {
        "id": "VQ3kvIRRgR5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(googletrans.LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RPqhpY7gdlv",
        "outputId": "a75414fa-6fa0-4fd1-a3f7-04606a3017f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'af': 'afrikaans', 'sq': 'albanian', 'am': 'amharic', 'ar': 'arabic', 'hy': 'armenian', 'az': 'azerbaijani', 'eu': 'basque', 'be': 'belarusian', 'bn': 'bengali', 'bs': 'bosnian', 'bg': 'bulgarian', 'ca': 'catalan', 'ceb': 'cebuano', 'ny': 'chichewa', 'zh-cn': 'chinese (simplified)', 'zh-tw': 'chinese (traditional)', 'co': 'corsican', 'hr': 'croatian', 'cs': 'czech', 'da': 'danish', 'nl': 'dutch', 'en': 'english', 'eo': 'esperanto', 'et': 'estonian', 'tl': 'filipino', 'fi': 'finnish', 'fr': 'french', 'fy': 'frisian', 'gl': 'galician', 'ka': 'georgian', 'de': 'german', 'el': 'greek', 'gu': 'gujarati', 'ht': 'haitian creole', 'ha': 'hausa', 'haw': 'hawaiian', 'iw': 'hebrew', 'he': 'hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hu': 'hungarian', 'is': 'icelandic', 'ig': 'igbo', 'id': 'indonesian', 'ga': 'irish', 'it': 'italian', 'ja': 'japanese', 'jw': 'javanese', 'kn': 'kannada', 'kk': 'kazakh', 'km': 'khmer', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'lo': 'lao', 'la': 'latin', 'lv': 'latvian', 'lt': 'lithuanian', 'lb': 'luxembourgish', 'mk': 'macedonian', 'mg': 'malagasy', 'ms': 'malay', 'ml': 'malayalam', 'mt': 'maltese', 'mi': 'maori', 'mr': 'marathi', 'mn': 'mongolian', 'my': 'myanmar (burmese)', 'ne': 'nepali', 'no': 'norwegian', 'or': 'odia', 'ps': 'pashto', 'fa': 'persian', 'pl': 'polish', 'pt': 'portuguese', 'pa': 'punjabi', 'ro': 'romanian', 'ru': 'russian', 'sm': 'samoan', 'gd': 'scots gaelic', 'sr': 'serbian', 'st': 'sesotho', 'sn': 'shona', 'sd': 'sindhi', 'si': 'sinhala', 'sk': 'slovak', 'sl': 'slovenian', 'so': 'somali', 'es': 'spanish', 'su': 'sundanese', 'sw': 'swahili', 'sv': 'swedish', 'tg': 'tajik', 'ta': 'tamil', 'te': 'telugu', 'th': 'thai', 'tr': 'turkish', 'uk': 'ukrainian', 'ur': 'urdu', 'ug': 'uyghur', 'uz': 'uzbek', 'vi': 'vietnamese', 'cy': 'welsh', 'xh': 'xhosa', 'yi': 'yiddish', 'yo': 'yoruba', 'zu': 'zulu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator=Translator()\n",
        "text=\"നീ എന്ത് ചെയ്യുന്നു\"\n",
        "lang=translator.detect(text).lang\n",
        "print(lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgRleVxTggIH",
        "outputId": "b65e6e9b-9eb6-49eb-ca1e-ece0816589e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_text=translator.translate(text,src=lang,dest='en')\n",
        "print(translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_QgHqcigmn-",
        "outputId": "9588fdac-6949-4d91-aeee-f4c0d576c783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated(src=ml, dest=en, text=what do you do, pronunciation=None, extra_data=\"{'confiden...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2997kE3Mgxd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}